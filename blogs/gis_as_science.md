---
layout: page
title: GIS as Reproducible Science
---

This week, we considered the question of how to categorize GIS (as in geographic information *systems*). Is it a tool or is it itself a science? The question of what it means to be “doing GIS” is a question I have never deeply considered, but is quite an important one.

 Wright et al. (2010) state that GIS can be considered under three different categories: as a tool, as toolmaking, or as a subject of study or science.

Thinking of GIS as a tool seems to be equivalent to seeing these “systems” as computer applications and associated techniques that only gain meaning when scientists apply scientific knowledge to them (Wright et al., 2010). In this context, GIS is more related to solving, rather than understanding, problems. Based on my academic experiences, “doing GIS” as a means to “do geography” seems to be a reasonable stance to take on this issue. The tool is a neutral, yet essential and informed, aspect of the process of investigation. Importantly, the use of GIS, which is not in this case a science, does not impart the assumed validity associated with "doing science."

One comment in this article really stood out to me: “GIS is the application of spatial science to the study of earthbound objects” (Wright et al., 2010). I think this resonated with many of the experiences I have had while learning GIS: I have been working mostly in a GUI format and view the GIS element of a task as a means to an end (in other words, I have implicitly learned to understand that GIS is a tool). Since we use GIS to represent and analyze data to test theories about the physical world, I have a hard time disentangling GIS from the overall study of geography and other disciplines like remote sensing and cartography (essentially, as a method to “do science”). This might be because I have no real experience with software development; I could see how that aspect of GIS could certainly count as a science.  

Perhaps this class and my remote sensing class last semester venture into the territory of GIS as toolmaking. In our most recent lab, we needed to develop a tool to answer the question at hand; thus, that development was inseparable from the process of solving the problem.

Thinking of GIS as a science entails using GIS to develop and test theories (Wright et al., 2010). The use of GIS as a tool is grounded in scientifically proven concepts, and the development of GIS can be thought of as science. Breakthroughs and developments in GIS design could certainly be counted as scientific, as they further the capabilities of knowledge generation. The “GIS as engineering” argument is applicable here, though. GIS and engineering are both methods of “problem-solving” (Wright et al., 2010), but those methods of development are grounded in scientific and well-tested principles. (Likewise, “the design PRINCIPLES of GIS are ‘scientific’” [Wright et al., 2010]).

In order to make any headway with this argument, it is important to try and pin down a definition of “science,” which is very difficult in and of itself. “Rigorous collection and evaluation of data in the production of knowledge” as per Karl Popper’s “‘positivism’” and “’critical rationalism’” (1959) (c.b. Wright et al., 2010) seems a fitting definition; however, as mentioned in class, historic ways of categorizing "science" vs. "not science" are often subject to gatekeeping and problematic biases. As Prof. Holler mentioned, science is always subject to rules, but those rules often differ by field of study. "Doing science" does not *always* involve following the structure of the scientific method. I therefore don't feel qualified to define something as "science" when I am not entirely sure what exactly science *is*.

Regardless of how you categorize GIS, in terms of the reproducibility crisis currently facing the modern scientific community, there is certainly a place for Open Source GIS in the scientific world.

 According to the National Academies of Sciences, Engineering, and Medicine (2019):
"Reproducibility is obtaining consistent results using the same input data; computational steps, methods, and code; and conditions of analysis. This definition is synonymous with “computational reproducibility,” and the terms are used interchangeably in this report. Replicability is obtaining consistent results across studies aimed at answering the same scientific question, each of which has obtained its own data."

Replicability is a hallmark of good science (National Academies of Sciences, Engineering, and Medicine, 2019), and as science is intended to be a communal effort to increase human understanding of the world around us and solve pressing problems, it goes without saying that reproducibility and replicability should always be emphasized when "doing science." The example we considered in class of the [ESRI tool](https://www.esri.com/en-us/covid-19/response) designed to determine the best locations of COVID testing sites was an example of how the use of highly useful technology can be limited by gatekeeping (be it financial or otherwise) and therefore not be truly communal or available to be evaluated or confirmed by the greater community.

Science is a process of building knowledge upon previous knowledge. Without clear methods and provision of data for checking analyses, simple yet important mistakes might not be caught, or methods may not be replicated with different data in order to determine the bounds within which a scientific theory applies (as we discussed in class yesterday).


- “Science is a mode of inquiry that aims to pose questions about the world, arriving at the answers and assessing their degree of certainty through a communal effort designed to ensure that they are well-grounded”
- Describe, explain, predict, or intervene

Different scientific disciplines are distinguished by the  types of tools, methods and techniques

Progress = desire for understanding is guided by core principles and methods

Reproducibility = enhanced integrity

**Science is a communal enterprise**
- Clear methods and results means understanding how to interpret the results, how to build on them, and how to check them
Science is durable and mutable: change is inevitable as scientists develop better methods for measuring and observing the world
- Knowledge is built on previous studies

Ease tension between replicability and discover (novel results could be reproduced)
- This is good for advancement of body of scientific knowledge

Reproducibility and Replicability

- Large amounts of data and computing resources
    - Democratization of data and computation —> new ways to conduct research
- Pressure to publish
    - Pressure to overstate the importance of results?
    - OpenSource checking removes this bias (easy to reproduce)
- Checking minor mistakes in code that can lead to error in results
- A lack of data code and method descriptions certainly exists
- Reproducible research: provides complete digital compendium of data and code to reproduce analysis

A: The terms are used with no distinction between them.
* B1:  “Reproducibility” refers to instances in which the original re- searcher’s data and computer codes are used to regenerate the results, while “replicability” refers to instances in which a re- searcher collects new data to arrive at the same scientific findings as a previous study.
* B2:  “Reproducibility” refers to independent researchers arriving at the same results using their own data and methods, while “rep- licability” refers to a different team arriving at the same results using the original author’s artifacts.
Results can be checked
Support original results
Same result in specific study context
Can the result be replicated in broader context

CompSci:
- Reproducible = can be checked bc data code and methods are available
- DEPENDS ON ACTION BY ANOTHER RESEARCHER
