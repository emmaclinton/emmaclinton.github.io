---
layout: page
title: Managing Error and Uncertainty
---

This week, we considered the question of how to manage error and uncertainty in geographic analyses. I have had experience with considering uncertainty in my geography classes at Middlebury. For instance, I enjoyed the section in the [Longley et al. (2005)](https://github.com/GIS4DEV/literature/blob/master/Uncertainty%20Longley%20et%20al.pdf) reading about confusion matrices, which I recognized from the [Remote Sensing and Land Use](https://sites.middlebury.edu/rsportfolioeclinton/) course I took during the Fall 2020 semester. In Remote Sensing and in this course we have experienced comparing our results to similar outcomes (in Remote Sensing, we compared tree cover classifications to those of the [Hansen Tree Cover Loss Dataset](https://data.globalforestwatch.org/datasets/14228e6347c44f5691572169e9e107ad), and in this course we compared [our hospital catchments](https://emmaclinton.github.io/gravity/gravity.html) to those of the [Dartmouth Health Atlas](https://atlasdata.dartmouth.edu/downloads/supplemental#boundaries). I also have externally validated Origin-Destination matrix results with Google Maps outputs and my answers have been slightly off, which got me thinking about the concept of datasets with different lineages resulting in unsuspected errors. I considered uncertainty and errors when compiling data for my thesis but as most of my data came from the [Vermont Open Geodata Portal](https://geodata.vermont.gov/#data), a vetted data provider, I more or less assumed that errors would be minimal. I also feel unprepared to rigorously evaluate data for errors.

I appreciated that the reading mentioned the importance of acknowledging that errors are to be expected in GIS analyses. The idea of supplying caveats in reported results seems necessary, but I could also see how this would be a fine line to walk, especially in the current context of academic pressure to publish significant and confident results. I think it must be difficult to make "advancements" in the field of geography when there are so many caveats to a given finding without a great deal of replication (which, of course, links back to the core concept of replicability and reproducibility as core tenets of good science).

It is necessary to acknowledge uncertainty, especially when you are publishing work that others might rely on or build on. Contained within that necessity, therefore, is the responsibility to have some idea of the scope of the impacts of error on output [Longley et al. (2005)](https://github.com/GIS4DEV/literature/blob/master/Uncertainty%20Longley%20et%20al.pdf) and to assess the quality of data. This should be a core aspect of geographic education, especially for those going on to do research. I appreciated learning about confusion matrices in Remote Sensing, as without this form of validating an output, it feels as though a researcher is putting blind trust into the output of their analysis.



Readings:

Longley, P. A., M. F. Goodchild, D. J. Maguire, and D. W. Rhind. 2008. Geographical information systems and science 2nd ed. Chichester: Wiley. Print.
